"""
Vulnerability Differ Service
Compares two vulnerability scans to identify fixed, new, and persistent issues
"""

import logging
from typing import Dict, List, Set, Tuple
from datetime import datetime

logger = logging.getLogger(__name__)

class VulnerabilityDiffer:
    """
    Service to compare vulnerability scans and generate diff reports
    """
    
    def __init__(self):
        self.comparison_strategies = {
            'exact_match': self._exact_match_strategy,
            'component_cve': self._component_cve_strategy,
            'component_severity': self._component_severity_strategy,
            'fuzzy_match': self._fuzzy_match_strategy
        }
    
    def analyze_differences(
        self, 
        old_vulnerabilities: List[Dict], 
        new_vulnerabilities: List[Dict],
        strategy: str = 'component_cve'
    ) -> Dict:
        """
        Analyze differences between two vulnerability scans
        
        Args:
            old_vulnerabilities: Previous scan results
            new_vulnerabilities: Current scan results
            strategy: Matching strategy to use
            
        Returns:
            Dict containing fixed, new, and persistent vulnerabilities
        """
        logger.info(f"Analyzing differences: {len(old_vulnerabilities)} old vs {len(new_vulnerabilities)} new vulnerabilities")
        
        # Use selected strategy to match vulnerabilities
        match_strategy = self.comparison_strategies.get(strategy, self._component_cve_strategy)
        
        # Create sets for comparison
        old_vuln_keys = set()
        new_vuln_keys = set()
        old_vuln_map = {}
        new_vuln_map = {}
        
        # Process old vulnerabilities
        for vuln in old_vulnerabilities:
            key = match_strategy(vuln)
            old_vuln_keys.add(key)
            old_vuln_map[key] = vuln
        
        # Process new vulnerabilities
        for vuln in new_vulnerabilities:
            key = match_strategy(vuln)
            new_vuln_keys.add(key)
            new_vuln_map[key] = vuln
        
        # Calculate differences
        fixed_keys = old_vuln_keys - new_vuln_keys
        new_keys = new_vuln_keys - old_vuln_keys
        persistent_keys = old_vuln_keys & new_vuln_keys
        
        # Build result
        result = {
            'old_vulnerabilities': old_vulnerabilities,
            'new_vulnerabilities': new_vulnerabilities,
            'fixed': [old_vuln_map[key] for key in fixed_keys],
            'new': [new_vuln_map[key] for key in new_keys],
            'persistent': [new_vuln_map[key] for key in persistent_keys],
            'summary': {
                'total_old': len(old_vulnerabilities),
                'total_new': len(new_vulnerabilities),
                'fixed_count': len(fixed_keys),
                'new_count': len(new_keys),
                'persistent_count': len(persistent_keys),
                'strategy_used': strategy
            },
            'metrics': self._calculate_metrics(old_vulnerabilities, new_vulnerabilities, fixed_keys, new_keys, persistent_keys),
            'severity_analysis': self._analyze_severity_changes(old_vuln_map, new_vuln_map, fixed_keys, new_keys, persistent_keys),
            'recommendations': self._generate_recommendations(new_vuln_map, persistent_keys, new_keys)
        }
        
        logger.info(f"Diff analysis complete: {len(fixed_keys)} fixed, {len(new_keys)} new, {len(persistent_keys)} persistent")
        
        return result
    
    def generate_actionable_report(self, diff_result: Dict) -> Dict:
        """
        Generate an actionable report focusing on what needs to be done
        
        Returns:
            Dict with prioritized actions and recommendations
        """
        new_vulns = diff_result['new']
        persistent_vulns = diff_result['persistent']
        
        # Prioritize by severity and fixability
        high_priority = []
        medium_priority = []
        low_priority = []
        
        all_actionable = new_vulns + persistent_vulns
        
        for vuln in all_actionable:
            severity = vuln.get('severity', 'UNKNOWN').upper()
            has_fix = bool(vuln.get('fixed_version'))
            
            priority_score = self._calculate_priority_score(vuln)
            
            if priority_score >= 80:
                high_priority.append(vuln)
            elif priority_score >= 50:
                medium_priority.append(vuln)
            else:
                low_priority.append(vuln)
        
        # Sort each priority group by severity
        severity_order = {'CRITICAL': 4, 'HIGH': 3, 'MEDIUM': 2, 'LOW': 1, 'INFO': 0, 'UNKNOWN': 0}
        
        for priority_list in [high_priority, medium_priority, low_priority]:
            priority_list.sort(key=lambda v: severity_order.get(v.get('severity', 'UNKNOWN').upper(), 0), reverse=True)
        
        actionable_report = {
            'timestamp': datetime.now().isoformat(),
            'needs_immediate_attention': len(high_priority),
            'can_be_scheduled': len(medium_priority),
            'low_priority_items': len(low_priority),
            'auto_fixable': len([v for v in all_actionable if v.get('fixed_version')]),
            'priority_groups': {
                'high_priority': {
                    'count': len(high_priority),
                    'vulnerabilities': high_priority,
                    'recommendation': 'Fix immediately - these pose significant security risks'
                },
                'medium_priority': {
                    'count': len(medium_priority),
                    'vulnerabilities': medium_priority,
                    'recommendation': 'Schedule for next maintenance window'
                },
                'low_priority': {
                    'count': len(low_priority),
                    'vulnerabilities': low_priority,
                    'recommendation': 'Monitor and fix when convenient'
                }
            },
            'auto_fix_candidates': [v for v in all_actionable if v.get('fixed_version')],
            'manual_review_required': [v for v in all_actionable if not v.get('fixed_version')],
            'estimated_effort': self._estimate_fix_effort(all_actionable),
            'risk_assessment': self._assess_risk(all_actionable)
        }
        
        return actionable_report
    
    def _exact_match_strategy(self, vulnerability: Dict) -> str:
        """Exact match strategy - matches on multiple fields"""
        component = vulnerability.get('component', 'unknown')
        version = vulnerability.get('current_version', 'unknown')
        vuln_id = vulnerability.get('id', vulnerability.get('name', 'unknown'))
        
        return f"{component}:{version}:{vuln_id}"
    
    def _component_cve_strategy(self, vulnerability: Dict) -> str:
        """Match on component and CVE ID (most reliable)"""
        component = vulnerability.get('component', 'unknown')
        cve_id = vulnerability.get('cve_id', vulnerability.get('id', vulnerability.get('name', 'unknown')))
        
        return f"{component}:{cve_id}"
    
    def _component_severity_strategy(self, vulnerability: Dict) -> str:
        """Match on component and severity (less precise)"""
        component = vulnerability.get('component', 'unknown')
        severity = vulnerability.get('severity', 'unknown')
        
        return f"{component}:{severity}"
    
    def _fuzzy_match_strategy(self, vulnerability: Dict) -> str:
        """Fuzzy matching strategy - more forgiving"""
        component = vulnerability.get('component', 'unknown').lower().strip()
        # Try to extract base component name
        if ':' in component:
            component = component.split(':')[-1]  # Take artifact ID part
        
        # Use description or CVE for secondary matching
        secondary = vulnerability.get('cve_id') or vulnerability.get('description', '')[:50]
        
        return f"{component}:{secondary}"
    
    def _calculate_metrics(self, old_vulns: List[Dict], new_vulns: List[Dict], 
                          fixed_keys: Set, new_keys: Set, persistent_keys: Set) -> Dict:
        """Calculate diff metrics"""
        total_old = len(old_vulns)
        total_new = len(new_vulns)
        
        # Calculate rates
        fix_rate = (len(fixed_keys) / max(1, total_old)) * 100
        new_rate = (len(new_keys) / max(1, total_new)) * 100
        persistence_rate = (len(persistent_keys) / max(1, total_old)) * 100
        
        # Calculate net change
        net_change = total_new - total_old
        net_change_percent = (net_change / max(1, total_old)) * 100
        
        return {
            'fix_rate_percent': round(fix_rate, 2),
            'new_vulnerability_rate_percent': round(new_rate, 2),
            'persistence_rate_percent': round(persistence_rate, 2),
            'net_change': net_change,
            'net_change_percent': round(net_change_percent, 2),
            'improvement_score': round(fix_rate - new_rate, 2)  # Positive is good
        }
    
    def _analyze_severity_changes(self, old_vuln_map: Dict, new_vuln_map: Dict,
                                 fixed_keys: Set, new_keys: Set, persistent_keys: Set) -> Dict:
        """Analyze severity distribution changes"""
        def count_by_severity(vuln_map: Dict, keys: Set) -> Dict:
            counts = {'CRITICAL': 0, 'HIGH': 0, 'MEDIUM': 0, 'LOW': 0, 'INFO': 0, 'UNKNOWN': 0}
            for key in keys:
                severity = vuln_map[key].get('severity', 'UNKNOWN').upper()
                counts[severity] = counts.get(severity, 0) + 1
            return counts
        
        fixed_by_severity = count_by_severity(old_vuln_map, fixed_keys)
        new_by_severity = count_by_severity(new_vuln_map, new_keys)
        persistent_by_severity = count_by_severity(new_vuln_map, persistent_keys)
        
        return {
            'fixed_by_severity': fixed_by_severity,
            'new_by_severity': new_by_severity,
            'persistent_by_severity': persistent_by_severity,
            'critical_trend': new_by_severity['CRITICAL'] - fixed_by_severity['CRITICAL'],
            'high_trend': new_by_severity['HIGH'] - fixed_by_severity['HIGH']
        }
    
    def _generate_recommendations(self, new_vuln_map: Dict, persistent_keys: Set, new_keys: Set) -> List[str]:
        """Generate actionable recommendations"""
        recommendations = []
        
        # Count by categories
        all_actionable_keys = persistent_keys | new_keys
        auto_fixable = 0
        critical_high = 0
        
        for key in all_actionable_keys:
            vuln = new_vuln_map[key]
            if vuln.get('fixed_version'):
                auto_fixable += 1
            if vuln.get('severity', '').upper() in ['CRITICAL', 'HIGH']:
                critical_high += 1
        
        # Generate specific recommendations
        if auto_fixable > 0:
            recommendations.append(
                f"ðŸ”§ {auto_fixable} vulnerabilities can be automatically fixed using VulnFixer"
            )
        
        if critical_high > 0:
            recommendations.append(
                f"ðŸš¨ {critical_high} CRITICAL/HIGH severity vulnerabilities require immediate attention"
            )
        
        if len(persistent_keys) > 0:
            recommendations.append(
                f"âš ï¸ {len(persistent_keys)} vulnerabilities persist from previous scan - investigate why they weren't fixed"
            )
        
        if len(new_keys) > len(persistent_keys):
            recommendations.append(
                "ðŸ“ˆ More new vulnerabilities than persistent ones detected - review development practices"
            )
        
        if not auto_fixable and len(all_actionable_keys) > 0:
            recommendations.append(
                "ðŸ” No automatically fixable vulnerabilities found - manual review required for all issues"
            )
        
        return recommendations
    
    def _calculate_priority_score(self, vulnerability: Dict) -> int:
        """Calculate priority score (0-100) for vulnerability"""
        score = 0
        
        # Severity scoring (40 points max)
        severity_scores = {
            'CRITICAL': 40,
            'HIGH': 30,
            'MEDIUM': 20,
            'LOW': 10,
            'INFO': 5
        }
        score += severity_scores.get(vulnerability.get('severity', '').upper(), 0)
        
        # Has fix available (30 points)
        if vulnerability.get('fixed_version'):
            score += 30
        
        # Direct dependency (15 points)
        if vulnerability.get('type') == 'direct':
            score += 15
        
        # Has CVE (10 points)
        if vulnerability.get('cve_id'):
            score += 10
        
        # Component criticality (5 points)
        component = vulnerability.get('component', '').lower()
        critical_components = ['spring', 'jackson', 'log4j', 'netty', 'junit']
        if any(comp in component for comp in critical_components):
            score += 5
        
        return min(score, 100)
    
    def _estimate_fix_effort(self, vulnerabilities: List[Dict]) -> Dict:
        """Estimate effort required to fix vulnerabilities"""
        auto_fixable = len([v for v in vulnerabilities if v.get('fixed_version')])
        manual_review = len(vulnerabilities) - auto_fixable
        
        # Estimate in person-hours
        auto_fix_time = auto_fixable * 0.5  # 30 minutes per auto fix (including testing)
        manual_time = manual_review * 4  # 4 hours per manual investigation
        
        return {
            'auto_fixable_count': auto_fixable,
            'manual_review_count': manual_review,
            'estimated_auto_fix_hours': round(auto_fix_time, 1),
            'estimated_manual_hours': round(manual_time, 1),
            'total_estimated_hours': round(auto_fix_time + manual_time, 1),
            'recommended_approach': 'Start with auto-fixes, then tackle manual reviews' if auto_fixable > 0 else 'All vulnerabilities require manual review'
        }
    
    def _assess_risk(self, vulnerabilities: List[Dict]) -> Dict:
        """Assess overall security risk"""
        total = len(vulnerabilities)
        if total == 0:
            return {'risk_level': 'LOW', 'justification': 'No vulnerabilities to assess'}
        
        critical_count = len([v for v in vulnerabilities if v.get('severity') == 'CRITICAL'])
        high_count = len([v for v in vulnerabilities if v.get('severity') == 'HIGH'])
        
        critical_ratio = critical_count / total
        high_ratio = high_count / total
        
        # Risk assessment logic
        if critical_ratio > 0.1 or critical_count > 5:
            risk_level = 'CRITICAL'
            justification = f'{critical_count} critical vulnerabilities present'
        elif high_ratio > 0.2 or high_count > 10:
            risk_level = 'HIGH'
            justification = f'{high_count} high severity vulnerabilities present'
        elif (critical_count + high_count) > 0:
            risk_level = 'MEDIUM'
            justification = f'{critical_count + high_count} critical/high vulnerabilities present'
        else:
            risk_level = 'LOW'
            justification = 'No critical or high severity vulnerabilities'
        
        return {
            'risk_level': risk_level,
            'justification': justification,
            'critical_vulnerabilities': critical_count,
            'high_vulnerabilities': high_count,
            'risk_score': min(100, (critical_count * 20) + (high_count * 10))
        }
    
    def find_regression_candidates(self, diff_result: Dict) -> List[Dict]:
        """
        Find vulnerabilities that might be regressions (similar to previously fixed ones)
        """
        fixed_vulns = diff_result['fixed']
        new_vulns = diff_result['new']
        
        regression_candidates = []
        
        for new_vuln in new_vulns:
            new_component = new_vuln.get('component', '')
            new_severity = new_vuln.get('severity', '')
            
            for fixed_vuln in fixed_vulns:
                fixed_component = fixed_vuln.get('component', '')
                fixed_severity = fixed_vuln.get('severity', '')
                
                # Check if same component with similar or worse severity
                if (new_component == fixed_component and 
                    self._severity_score_numeric(new_severity) >= self._severity_score_numeric(fixed_severity)):
                    
                    regression_candidates.append({
                        'new_vulnerability': new_vuln,
                        'previously_fixed': fixed_vuln,
                        'regression_type': 'same_component',
                        'confidence': 'high' if new_severity == fixed_severity else 'medium'
                    })
                    break
        
        return regression_candidates
    
    def _severity_score_numeric(self, severity: str) -> int:
        """Convert severity to numeric score for comparison"""
        scores = {'CRITICAL': 4, 'HIGH': 3, 'MEDIUM': 2, 'LOW': 1, 'INFO': 0, 'UNKNOWN': 0}
        return scores.get(severity.upper(), 0)
